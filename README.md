# ğŸ“Š CUDA â€“ NotaÃ§Ã£o, CÃ¡lculo & Anatomia do Algoritmo

Pequeno projeto de programaÃ§Ã£o em GPUs: Soma de 128 nÃºmeros na GPU e geraÃ§Ã£o do resultado no formato de **tabela 8 Ã— 16** para exibir a paralelizaÃ§Ã£o.


---

## Objetivo do cÃ³digo

1. Aloja **128 floats** na CPU e na GPU.  
2. Preencche `x = 35.0`, `y = 34.0`.  
3. Executa kernel `add<<<blocks, threads>>>` â€“ **1 thread por elemento**.  
4. Devolve o vetor `z = x + y` (valor 3 em todas as posiÃ§Ãµes).  
5. Imprime **8 linhas Ã— 16 colunas** alinhadas.  
6. Mostra **tempo de execuÃ§Ã£o total** (alocaÃ§Ã£o â†’ cÃ³pia â†’ kernel â†’ cÃ³pia â†’ print).

---

## ğŸ”§ Requisitos

- GPU NVIDIA com Compute Capability â‰¥ 3.5  
- CUDA Toolkit instalado (provÃª `nvcc`)  
- Compilador C++ (g++ ou clang)  


## ğŸš€ CompilaÃ§Ã£o & execuÃ§Ã£o

Compilar:
```bash

nvcc -arch=sm_75 -std=c++17 -O3 cuda.cu -o cuda

./cuda
```


## ğŸ–¥ï¸ SaÃ­da esperada


```bash

./cuda
[GPU]: NVIDIA GeForce GTX 1650
[ComputaÃ§Ã£o]: 7.5
[Multiprocessadores]: 14
[Total CUDA Cores]: 896
[Kernel]: 6.82404ms

[Threads por bloco]: 1024

  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69
  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69  69

```


---


- **CÃ¡lculo**: soma elemento-a-elemento.  
- **NotaÃ§Ã£o**: Ã­ndices 1-D mapeados em 2-D por `lin = i / cols`, `col = i % cols`.  
- **Complexidade**: Î˜(N) trabalho, Î˜(N) trÃ¡fego de memÃ³ria.  
- **Visual**: tabela 8 Ã— 16 = confirmaÃ§Ã£o instantÃ¢nea de correÃ§Ã£o.


## 1. CÃ¡lculo

> **z = x + y**, onde **x = 35.0**, **y = 34.0** â†’ **z = 69.0** em **todas as 128 posiÃ§Ãµes**.

---

## 2. NotaÃ§Ã£o & ConvenÃ§Ãµes

| SÃ­mbolo | Significado | Valor aqui |
|---------|-------------|------------|
| **N** | total de elementos (threads) | 128 |
| **threads por bloco** | `blockDim.x` | 256 |
| **nÂº de blocos** | `gridDim.x` = `(N + 255) / 256` | 1 |
| **Ã­ndice global** | `int i = blockIdx.x * blockDim.x + threadIdx.x` | 0 â€¦ 127 |
| **Ã­ndice local** | `threadIdx.x` | 0 â€¦ 255 (mas sÃ³ 0-127 vÃ¡lido) |

---

## 3. Fluxo de Dados 

```
CPU (HOST)                     GPU (DEVICE)
â”Œ-------------â”               â”Œ-------------â”
â”‚ h_x = 1.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_x         â”‚
â”‚ h_y = 2.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_y         â”‚
â”‚             â”‚               â”‚ d_z         â”‚
â”‚ h_z (vazio) â”‚â—€-cudaMemcpy-â–ºâ”‚ d_z â† add() â”‚
â””-------------â”˜               â””-------------â”˜
```

---

## 4. Kernel â€“ Algebricamente

Kernel `add`:

```
âˆ€ i âˆˆ [0, N âˆ’ 1] :
    z[i] â† x[i] + y[i]
```

ImplementaÃ§Ã£o SIMT:

```
i â† blockIdxÂ·blockDim + threadIdx
if i < N :
    z[i] â† x[i] + y[i]
```

A condiÃ§Ã£o `if` evita **out-of-bounds** quando `N` nÃ£o Ã© mÃºltiplo de `blockDim`.

---

## 5. Complexidade & MÃ©tricas

| Grandeza | Valor | NotaÃ§Ã£o |
|----------|-------|---------|
| **Work-items** | 128 | O(N) |
| **InstruÃ§Ãµes** | 1 add / thread | O(1) por thread |
| **MemÃ³ria lida** | 2Â·NÂ·4 B = 1 024 B | Î˜(N) |
| **MemÃ³ria escrita** | NÂ·4 B = 512 B | Î˜(N) |
| **Tempo medido** | â‰ˆ 4 ms (GTX 1650) | T(N) = Î˜(N) |

---

## 6. Warm-up & SincronizaÃ§Ã£o

- `cudaDeviceSynchronize()` apÃ³s o kernel = **barreira global** â€“ CPU sÃ³ prossegue quando **todas as threads** terminaram.  
- Sem ela o cronÃ´metro mediria **sÃ³ o lanÃ§amento**, nÃ£o a execuÃ§Ã£o.

---

## 7. Visual

- 128 = 2â· â†’ fatoraÃ§Ã£o 2â´ Ã— 2Â³ = 16 Ã— 8 gera **tabela quadrada visualmente agradÃ¡vel**.  
- Facilita verificar de relance se **todos os elementos** estÃ£o corretos.
---


