# ğŸ“Š CUDA â€“ NotaÃ§Ã£o, CÃ¡lculo & Anatomia do Algoritmo

Pequeno projeto de programaÃ§Ã£o em GPUs: Soma de 128 nÃºmeros na GPU e geraÃ§Ã£o do resultado no formato de **tabela 8 Ã— 16** para exibir a paralelizaÃ§Ã£o.

---

## ğŸ“¦ O que estÃ¡ aqui

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `cuda-hello-table.cu` | CÃ³digo-fonte completo (C++17 + CUDA) |
| `Makefile` | Compila com um comando sÃ³ |
| `README.md` | Este arquivo |

---

## ğŸ¯ Objetivo do cÃ³digo

1. Aloja **128 floats** na CPU e na GPU.  
2. Preencche `x = 1.0`, `y = 2.0`.  
3. Executa kernel `add<<<blocks, 256>>>` â€“ **1 thread por elemento**.  
4. Devolve o vetor `z = x + y` (valor 3 em todas as posiÃ§Ãµes).  
5. Imprime **8 linhas Ã— 16 colunas** alinhadas.  
6. Mostra **tempo de execuÃ§Ã£o total** (alocaÃ§Ã£o â†’ cÃ³pia â†’ kernel â†’ cÃ³pia â†’ print).

---

## ğŸ”§ Requisitos

- GPU NVIDIA com Compute Capability â‰¥ 3.5  
- CUDA Toolkit instalado (provÃª `nvcc`)  
- Compilador C++ (g++ ou clang)  


## ğŸš€ CompilaÃ§Ã£o & execuÃ§Ã£o

Compilar:
```bash
nvcc -arch=sm_75 -std=c++17 -O3 cuda-hello-table.cu -o cuda-hello-table
./cuda-hello-table
```


## ğŸ–¥ï¸ SaÃ­da esperada

```
Resultado: 
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3
[INFO]: 4 ms
```

---


| Tarefa | O que aprenderÃ¡ |
|--------|-----------------|
| Altere `N` para 1 048 576 | Grande escalabilidade |
| Troque `threads` 256 â†’ 512 / 1024 | Escolha ideal de bloco |
| Use `cudaMallocManaged` | Unified Memory (menos cÃ³pias) |
| Adicione `__shared__ float buf[256]` | MemÃ³ria compartilhada |
| Troque `add` por `axpy` (y = a*x + y) | BLAS nÃ­vel 1 |



---

- **CÃ¡lculo**: soma elemento-a-elemento.  
- **NotaÃ§Ã£o**: Ã­ndices 1-D mapeados em 2-D por `lin = i / cols`, `col = i % cols`.  
- **Complexidade**: Î˜(N) trabalho, Î˜(N) trÃ¡fego de memÃ³ria.  
- **Visual**: tabela 8 Ã— 16 = confirmaÃ§Ã£o instantÃ¢nea de correÃ§Ã£o.


## 1. CÃ¡lculo

> **z = x + y**, onde **x = 1.0**, **y = 2.0** â†’ **z = 3.0** em **todas as 128 posiÃ§Ãµes**.

---

## 2. NotaÃ§Ã£o & ConvenÃ§Ãµes

| SÃ­mbolo | Significado | Valor aqui |
|---------|-------------|------------|
| **N** | total de elementos (threads) | 128 |
| **threads por bloco** | `blockDim.x` | 256 |
| **nÂº de blocos** | `gridDim.x` = `(N + 255) / 256` | 1 |
| **Ã­ndice global** | `int i = blockIdx.x * blockDim.x + threadIdx.x` | 0 â€¦ 127 |
| **Ã­ndice local** | `threadIdx.x` | 0 â€¦ 255 (mas sÃ³ 0-127 vÃ¡lido) |

---

## 3. Fluxo de Dados 

```
CPU (HOST)                     GPU (DEVICE)
â”Œ-------------â”               â”Œ-------------â”
â”‚ h_x = 1.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_x         â”‚
â”‚ h_y = 2.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_y         â”‚
â”‚             â”‚               â”‚ d_z         â”‚
â”‚ h_z (vazio) â”‚â—€-cudaMemcpy-â–ºâ”‚ d_z â† add() â”‚
â””-------------â”˜               â””-------------â”˜
```

---

## 4. Kernel â€“ Algebricamente

Kernel `add`:

```
âˆ€ i âˆˆ [0, N âˆ’ 1] :
    z[i] â† x[i] + y[i]
```

ImplementaÃ§Ã£o SIMT:

```
i â† blockIdxÂ·blockDim + threadIdx
if i < N :
    z[i] â† x[i] + y[i]
```

A condiÃ§Ã£o `if` evita **out-of-bounds** quando `N` nÃ£o Ã© mÃºltiplo de `blockDim`.

---

## 5. Complexidade & MÃ©tricas

| Grandeza | Valor | NotaÃ§Ã£o |
|----------|-------|---------|
| **Work-items** | 128 | O(N) |
| **InstruÃ§Ãµes** | 1 add / thread | O(1) por thread |
| **MemÃ³ria lida** | 2Â·NÂ·4 B = 1 024 B | Î˜(N) |
| **MemÃ³ria escrita** | NÂ·4 B = 512 B | Î˜(N) |
| **Tempo medido** | â‰ˆ 4 ms (GTX 1650) | T(N) = Î˜(N) |

---

## 6. Warm-up & SincronizaÃ§Ã£o

- `cudaDeviceSynchronize()` apÃ³s o kernel = **barreira global** â€“ CPU sÃ³ prossegue quando **todas as threads** terminaram.  
- Sem ela o cronÃ´metro mediria **sÃ³ o lanÃ§amento**, nÃ£o a execuÃ§Ã£o.

---

## 7. Visual

- 128 = 2â· â†’ fatoraÃ§Ã£o 2â´ Ã— 2Â³ = 16 Ã— 8 gera **tabela quadrada visualmente agradÃ¡vel**.  
- Facilita verificar de relance se **todos os elementos** estÃ£o corretos.
---


