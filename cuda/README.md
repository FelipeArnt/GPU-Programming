# ğŸ“Š CUDA--Table â€“ NotaÃ§Ã£o, CÃ¡lculo & Anatomia do Algoritmo

Pequeno projeto de programaap em GPUs: Foram somados 128 nÃºmeros na GPU e o resultado foi impresso no formato de **tabela 8 Ã— 16** para exibir a paralelizaÃ§Ã£o.

---

- **CÃ¡lculo**: soma elemento-a-elemento.  
- **NotaÃ§Ã£o**: Ã­ndices 1-D mapeados em 2-D por `lin = i / cols`, `col = i % cols`.  
- **Complexidade**: Î˜(N) trabalho, Î˜(N) trÃ¡fego de memÃ³ria.  
- **Visual**: tabela 8 Ã— 16 = confirmaÃ§Ã£o instantÃ¢nea de correÃ§Ã£o.


## 1. CÃ¡lculo

> **z = x + y**, onde **x = 1.0**, **y = 2.0** â†’ **z = 3.0** em **todas as 128 posiÃ§Ãµes**.

---

## 2. NotaÃ§Ã£o & ConvenÃ§Ãµes

| SÃ­mbolo | Significado | Valor aqui |
|---------|-------------|------------|
| **N** | total de elementos (threads) | 128 |
| **threads por bloco** | `blockDim.x` | 256 |
| **nÂº de blocos** | `gridDim.x` = `(N + 255) / 256` | 1 |
| **Ã­ndice global** | `int i = blockIdx.x * blockDim.x + threadIdx.x` | 0 â€¦ 127 |
| **Ã­ndice local** | `threadIdx.x` | 0 â€¦ 255 (mas sÃ³ 0-127 vÃ¡lido) |

---

## 3. Mapeamento Ãndice â‡¨ Tabela 2-D

Linha-major (row-major):

```
Ã­ndice 1-D:   0  1  2 â€¦ 15 | 16 â€¦ 31 | â€¦ | 112 â€¦ 127
tabela 2-D:  linha 0     | linha 1  | â€¦ | linha 7
```

FÃ³rmula de conversÃ£o:

```
lin = i / 16        (divisÃ£o inteira)
col = i % 16        (resto)
```

Por isso o laÃ§o de impressÃ£o Ã©:

```cpp
for (lin = 0 â€¦ 7)
    for (col = 0 â€¦ 15)
        print h_z[lin*16 + col]
```

---

## 4. Fluxo de Dados (esquema textual)

```
CPU (HOST)                     GPU (DEVICE)
â”Œ-------------â”               â”Œ-------------â”
â”‚ h_x = 1.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_x         â”‚
â”‚ h_y = 2.0   â”‚â”€â”€cudaMemcpyâ”€â”€â–ºâ”‚ d_y         â”‚
â”‚             â”‚               â”‚ d_z         â”‚
â”‚ h_z (vazio) â”‚â—€--cudaMemcpy--â”‚ d_z â† add() â”‚
â””-------------â”˜               â””-------------â”˜
```

---

## 5. Kernel â€“ Ãlgebricamente

Kernel `add`:

```
âˆ€ i âˆˆ [0, N âˆ’ 1] :
    z[i] â† x[i] + y[i]
```

ImplementaÃ§Ã£o SIMT:

```
i â† blockIdxÂ·blockDim + threadIdx
if i < N :
    z[i] â† x[i] + y[i]
```

A condiÃ§Ã£o `if` evita **out-of-bounds** quando `N` nÃ£o Ã© mÃºltiplo de `blockDim`.

---

## 6. Complexidade & MÃ©tricas

| Grandeza | Valor | NotaÃ§Ã£o |
|----------|-------|---------|
| **Work-items** | 128 | O(N) |
| **InstruÃ§Ãµes** | 1 add / thread | O(1) por thread |
| **MemÃ³ria lida** | 2Â·NÂ·4 B = 1 024 B | Î˜(N) |
| **MemÃ³ria escrita** | NÂ·4 B = 512 B | Î˜(N) |
| **Tempo medido** | â‰ˆ 4 ms (GTX 1650) | T(N) = Î˜(N) |

---

## 7. Warm-up & SincronizaÃ§Ã£o

- `cudaDeviceSynchronize()` apÃ³s o kernel = **barreira global** â€“ CPU sÃ³ prossegue quando **todas as threads** terminaram.  
- Sem ela o cronÃ´metro mediria **sÃ³ o lanÃ§amento**, nÃ£o a execuÃ§Ã£o.

---

## 8. Visual

- 128 = 2â· â†’ fatoraÃ§Ã£o 2â´ Ã— 2Â³ = 16 Ã— 8 gera **tabela quadrada visualmente agradÃ¡vel**.  
- Facilita verificar de relance se **todos os elementos** estÃ£o corretos (tudo 3).

---

## 9. PossÃ­veis VariaÃ§Ãµes DidÃ¡ticas

| AlteraÃ§Ã£o | Aprendizado |
|-----------|-------------|
| `N = 1 024` | Escalabilidade |
| `threads = 32` | Exato tamanho de **warp** |
| `__shared__ float buf[256]` | Introduz **memÃ³ria local** |
| `atomicAdd(&z[0], 1)` | ReduÃ§Ã£o e **concorrÃªncia** |
| `cudaMallocManaged` | **Unified Memory** â€“ zero cÃ³pias |

